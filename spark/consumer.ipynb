{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9962b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install vncorenlp\n",
    "# !pip install angdetect\n",
    "# !pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6c063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# This funtion will format \"publishedAtDate\" column for later usage\n",
    "def formatToDatetime(date_string):\n",
    "    date_string_without_fraction = date_string[:-5] + 'Z'\n",
    "    date_format = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "    return datetime.strptime(date_string_without_fraction, date_format)\n",
    "\n",
    "# How to apply to dataframe\n",
    "# df['date_column'] = df['date_column'].apply(lambda x: convert_to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b9f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "def removeOtherLanguage(data):\n",
    "    for i in range(len(data)):\n",
    "        try: \n",
    "            if detect(str(data.loc[i, 'text'])) != \"vi\":\n",
    "                #print(str(data.loc[i, 'text']), i)\n",
    "                data = data.drop(i)\n",
    "        except:\n",
    "            #print(str(data.loc[i, 'text']))\n",
    "            data = data.drop(i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553a757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeReplace(text):\n",
    "    replacements = {\n",
    "        \"òa\": \"oà\", \"óa\": \"oá\", \"ỏa\": \"oả\", \"õa\": \"oã\", \"ọa\": \"oạ\",\n",
    "        \"òe\": \"oè\", \"óe\": \"oé\", \"ỏe\": \"oẻ\", \"õe\": \"oẽ\", \"ọe\": \"oẹ\",\n",
    "        \"ùy\": \"uỳ\", \"úy\": \"uý\", \"ủy\": \"uỷ\", \"ũy\": \"uỹ\", \"ụy\": \"uỵ\",\n",
    "        \"Ủy\": \"Uỷ\", \"\\n\": \".\" , \"\\t\": \".\"  # Add more replacements as needed\n",
    "    }\n",
    "    for old, new in replacements.items():\n",
    "        text = text.replace(old, new)\n",
    "    return text\n",
    "\n",
    "def unicode(data):\n",
    "    data['text'] = data['text'].apply(unicodeReplace)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c5f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               u\"\\U000024C2-\\U0001F251\" \n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d019ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base Vietnamese alphabet without tone marks\n",
    "vietnamese_alphabet = \"aăâbcdđeêghiklmnoôơpqrstuưvwxy\"\n",
    "vietnamese_letter_with_tone = \"áàạãảắằẵẳặấầẩẫậéèẻẽẹềếểễệòóỏõọồốổỗộờớởỡợúùũủụứừửữựíìĩỉịýỳỹỷỵ\"\n",
    "\n",
    "# Create uppercase Vietnamese letters with tone marks\n",
    "uppercase_vietnamese_letters_with_tone = [char.upper() for char in vietnamese_letter_with_tone]\n",
    "uppercase_vietnamese_alphabet = vietnamese_alphabet.upper()\n",
    "\n",
    "# Combine the lists into strings\n",
    "lowercase_string = vietnamese_alphabet + \"\".join(vietnamese_letter_with_tone)\n",
    "uppercase_string = uppercase_vietnamese_alphabet + \"\".join(uppercase_vietnamese_letters_with_tone)\n",
    "allcase_string = lowercase_string + uppercase_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b39bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "punctuation = \"!\\\"#$%&'()*+,./:;<=>?@[\\]^_`{|}~\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3593c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stickyPreprocess(data):\n",
    "    def processText(text):\n",
    "        result = []\n",
    "        for letter_id in range(len(text) - 2):\n",
    "            prev, letter, after = text[letter_id], text[letter_id + 1], text[letter_id + 2]\n",
    "\n",
    "            if letter in punctuation:\n",
    "                if prev in allcase_string:\n",
    "                    result.append(letter_id + 1)\n",
    "                if after in allcase_string:\n",
    "                    result.append(letter_id + 2)\n",
    "\n",
    "            if letter in uppercase_string and prev in lowercase_string and letter_id != 0:\n",
    "                result.extend([letter_id, letter_id + 1])\n",
    "\n",
    "        for index in reversed(result):\n",
    "            text = text[:index] + \" \" + text[index:]\n",
    "\n",
    "        return text\n",
    "\n",
    "    data['text'] = data['text'].apply(processText)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e50c674",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Mapping' from 'collections' (C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\collections\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvncorenlp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VnCoreNLP\n\u001b[0;32m      2\u001b[0m annotator \u001b[38;5;241m=\u001b[39m VnCoreNLP(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../vncorenlp/VnCoreNLP-1.1.1.jar\u001b[39m\u001b[38;5;124m\"\u001b[39m, annotators\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwseg\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_heap_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-Xmx500m\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\vncorenlp\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/python\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvncorenlp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VNCORENLP_SERVER\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvncorenlp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VnCoreNLP\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\vncorenlp\\vncorenlp.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlparse\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RequestException\n\u001b[0;32m     13\u001b[0m __author__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdnanhkhoa\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\__init__.py:43\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mRequests HTTP Library\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m~~~~~~~~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m:license: Apache 2.0, see LICENSE for more details.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RequestsDependencyWarning\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\__init__.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectionpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     HTTPConnectionPool,\n\u001b[0;32m     10\u001b[0m     HTTPSConnectionPool,\n\u001b[0;32m     11\u001b[0m     connection_from_url\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilepost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m encode_multipart_formdata\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m six\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmoves\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m queue\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     port_by_scheme,\n\u001b[0;32m     31\u001b[0m     DummyConnection,\n\u001b[0;32m     32\u001b[0m     HTTPConnection, HTTPSConnection, VerifiedHTTPSConnection,\n\u001b[0;32m     33\u001b[0m     HTTPException, BaseSSLError,\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RequestMethods\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:39\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     NewConnectionError,\n\u001b[0;32m     33\u001b[0m     ConnectTimeoutError,\n\u001b[0;32m     34\u001b[0m     SubjectAltNameWarning,\n\u001b[0;32m     35\u001b[0m     SystemTimeWarning,\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mssl_match_hostname\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m match_hostname, CertificateError\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mssl_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     resolve_cert_reqs,\n\u001b[0;32m     41\u001b[0m     resolve_ssl_version,\n\u001b[0;32m     42\u001b[0m     assert_fingerprint,\n\u001b[0;32m     43\u001b[0m     create_urllib3_context,\n\u001b[0;32m     44\u001b[0m     ssl_wrap_socket\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m connection\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_collections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPHeaderDict\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# For backwards compatibility, provide imports that used to be here.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_connection_dropped\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_headers\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_fp_closed\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msocket\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwait\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wait_for_read\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselectors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HAS_SELECT, SelectorError\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_connection_dropped\u001b[39m(conn):  \u001b[38;5;66;03m# Platform-specific\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\wait.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselectors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     HAS_SELECT,\n\u001b[0;32m      3\u001b[0m     DefaultSelector,\n\u001b[0;32m      4\u001b[0m     EVENT_READ,\n\u001b[0;32m      5\u001b[0m     EVENT_WRITE\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_for_io_events\u001b[39m(socks, events, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Waits for IO events to be available from a list of sockets\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    or optionally a single socket if passed in. Returns a list of\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    sockets that can be interacted with immediately. \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\selectors.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m namedtuple, Mapping\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     monotonic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Mapping' from 'collections' (C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\collections\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from vncorenlp import VnCoreNLP\n",
    "annotator = VnCoreNLP(\"../vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dd12cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "abbreviation_dict = '../vncorenlp/abbreviation_dictionary_vn.xlsx'\n",
    "df = pd.read_csv('../vncorenlp/abbreviation_dictionary_vn.csv')\n",
    "abbreviation_dict = df.set_index(\"abbreviation\")[\"meaning\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b76cbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abbreviationPreprocess(data):\n",
    "    def replaceWord(word, dictionary):\n",
    "        return dictionary.get(word, word)\n",
    "\n",
    "    def processText(text):\n",
    "        annotator_text = annotator.tokenize(text)\n",
    "\n",
    "        tokens = [it for sublist in annotator_text for it in sublist if it != '_']\n",
    "        tokens = [replaceWord(it.lower(), abbreviation_dict) for it in tokens]\n",
    "\n",
    "        sentences = [' '.join(sublist) for sublist in annotator_text]\n",
    "\n",
    "        return pd.Series([' '.join(tokens), sentences], index=['text', 'sentences'])\n",
    "\n",
    "    data[['text', 'sentences']] = data['text'].apply(processText)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c7eb3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import underthesea\n",
    "\n",
    "def sentimentCal(sentences):\n",
    "    sentiments = [underthesea.sentiment(text) for text in sentences]\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03dd905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Ridge from version 1.3.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "model = joblib.load('../data_result/model.joblib')\n",
    "selected_columns = [\"pos_prop\", \"neg_prop\", \"reviewLength\", \"reviewHour\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3af62c0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "code() argument 13 must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfindspark\u001b[39;00m\n\u001b[0;32m      2\u001b[0m findspark\u001b[38;5;241m.\u001b[39minit()\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymongo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MongoClient\n",
      "File \u001b[1;32mD:\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\__init__.py:51\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkConf\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkContext\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrdd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RDD, RDDBarrier\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfiles\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkFiles\n",
      "File \u001b[1;32mD:\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\context.py:30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpy4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotocol\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Py4JError\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpy4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjava_gateway\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_instance_of\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accumulators\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccumulators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accumulator\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbroadcast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Broadcast, BroadcastPickleRegistry\n",
      "File \u001b[1;32mD:\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\accumulators.py:97\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msocketserver\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mSocketServer\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_int, PickleSerializer\n\u001b[0;32m    100\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccumulator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccumulatorParam\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    103\u001b[0m pickleSer \u001b[38;5;241m=\u001b[39m PickleSerializer()\n",
      "File \u001b[1;32mD:\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\serializers.py:71\u001b[0m\n\u001b[0;32m     68\u001b[0m     xrange \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m\n\u001b[0;32m     69\u001b[0m pickle_protocol \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mHIGHEST_PROTOCOL\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cloudpickle\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _exception_message, print_exec\n\u001b[0;32m     75\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPickleSerializer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarshalSerializer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTF8Deserializer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\cloudpickle.py:209\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m types\u001b[38;5;241m.\u001b[39mCodeType(\n\u001b[0;32m    192\u001b[0m                 co\u001b[38;5;241m.\u001b[39mco_argcount,\n\u001b[0;32m    193\u001b[0m                 co\u001b[38;5;241m.\u001b[39mco_kwonlyargcount,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m                 (),\n\u001b[0;32m    207\u001b[0m             )\n\u001b[1;32m--> 209\u001b[0m _cell_set_template_code \u001b[38;5;241m=\u001b[39m \u001b[43m_make_cell_set_template_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcell_set\u001b[39m(cell, value):\n\u001b[0;32m    213\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set the value of a closure cell.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mD:\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\cloudpickle.py:172\u001b[0m, in \u001b[0;36m_make_cell_set_template_code\u001b[1;34m()\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(types\u001b[38;5;241m.\u001b[39mCodeType, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mco_posonlyargcount\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# pragma: no branch\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCodeType\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_argcount\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_posonlyargcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Python3.8 with PEP570\u001b[39;49;00m\n\u001b[0;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_kwonlyargcount\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_nlocals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_stacksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_consts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_varnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_firstlineno\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_lnotab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_cellvars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# this is the trickery\u001b[39;49;00m\n\u001b[0;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m types\u001b[38;5;241m.\u001b[39mCodeType(\n\u001b[0;32m    192\u001b[0m             co\u001b[38;5;241m.\u001b[39mco_argcount,\n\u001b[0;32m    193\u001b[0m             co\u001b[38;5;241m.\u001b[39mco_kwonlyargcount,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m             (),\n\u001b[0;32m    207\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: code() argument 13 must be str, not int"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pymongo import MongoClient\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae2000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scala_version = '2.12'  # your scala version\n",
    "spark_version = '3.5.0' # your spark version\n",
    "packages = [\n",
    "    f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}',\n",
    "    'org.apache.kafka:kafka-clients:3.6.0' #your kafka version\n",
    "]\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"PREDICT_RATINGS_OF_GOOGLE_LOCAL_REVIEWS_IE212_O11_GROUP7\").config(\"spark.jars.packages\", \",\".join(packages)).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage of KafkaConsumer class\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "topic_name = 'PREDICT_RATINGS_OF_GOOGLE_LOCAL_REVIEWS_IE212_O11_GROUP7'\n",
    "\n",
    "kafkaDf = spark.read.format(\"kafka\").option(\"kafka.bootstrap.servers\", bootstrap_servers)\\\n",
    "                .option(\"subscribe\", topic_name)\\\n",
    "                .option(\"startingOffsets\", \"earliest\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local server\n",
    "client = MongoClient(\"mongodb://127.0.0.1:27017/\")\n",
    "\n",
    "# Create database called animals\n",
    "mydb = client[\"ie212_o11_group7\"]\n",
    "\n",
    "# Create Collection (table) called shelterA\n",
    "collection = mydb.reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b6e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from IPython.display import display, clear_output\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, ArrayType\n",
    "\n",
    "# Khởi tạo SparkSession\n",
    "spark = SparkSession.builder.appName(\"PREDICT_RATINGS_OF_GOOGLE_LOCAL_REVIEWS_IE212_O11_GROUP7\").getOrCreate()\n",
    "\n",
    "# Định nghĩa schema cho dữ liệu JSON\n",
    "json_schema = StructType([\n",
    "            StructField(\"reviewId\", StringType(), True),\n",
    "            StructField(\"placeId\", StringType(), True),\n",
    "            StructField(\"title\", StringType(), True),\n",
    "            StructField(\"location/lat\", DoubleType(), True),\n",
    "            StructField(\"location/lng\", DoubleType(), True),\n",
    "            StructField(\"categories\", StringType(), True),\n",
    "            StructField(\"categoryName\", StringType(), True),\n",
    "            StructField(\"reviewerId\", StringType(), True),\n",
    "            StructField(\"name\", StringType(), True),\n",
    "            StructField(\"stars\", IntegerType(), True),\n",
    "            StructField(\"text\", StringType(), True),\n",
    "            StructField(\"publishedAtDate\", StringType(), True),\n",
    "            StructField(\"last_update_time\", DoubleType(), True)\n",
    "            ])\n",
    "\n",
    "# Đọc dữ liệu từ Kafka topic và chuyển đổi thành DataFrame\n",
    "kafka_stream_df = spark.readStream.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", bootstrap_servers) \\\n",
    "    .option(\"subscribe\", topic_name) \\\n",
    "    .load()\n",
    "\n",
    "kafkaDf = spark.read.format(\"kafka\").option(\"kafka.bootstrap.servers\", bootstrap_servers)\\\n",
    "                .option(\"subscribe\", topic_name)\\\n",
    "                .option(\"startingOffsets\", \"earliest\").load()\n",
    "\n",
    "# Chuyển đổi giá trị từ JSON string sang struct với schema đã định nghĩa\n",
    "json_stream_df = kafkaDf.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(\"value\", json_schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")\n",
    "\n",
    "# Hàm callback để cập nhật average_rating\n",
    "def update_average_rating(row):\n",
    "    # Kết nối tới MongoDB\n",
    "    client = MongoClient(\"mongodb://127.0.0.1:27017/\")\n",
    "    mydb = client[\"ie212_o11_group7\"]\n",
    "    places_collection = mydb.places\n",
    "    \n",
    "    # Lấy thông tin từ row\n",
    "    place_id = row['placeId']\n",
    "    stars = row['stars'] or 0\n",
    "    predict_rating = row['Predict_rating']\n",
    "    \n",
    "    # Lấy thông tin từ MongoDB\n",
    "    place_info = places_collection.find_one({'placeId': place_id})\n",
    "    \n",
    "    if place_info:\n",
    "        total_rows = place_info['total_rows']\n",
    "\n",
    "        current_average_rating = place_info['average_rating']\n",
    "        new_average_rating = (current_average_rating * total_rows + stars) / (total_rows + 1)\n",
    "\n",
    "        # Tính toán average_rating_new\n",
    "        current_average_predict_rating = place_info['average_predict_rating']\n",
    "        new_average_predict_rating = (current_average_predict_rating * total_rows + predict_rating) / (total_rows + 1)\n",
    "        \n",
    "        # Cập nhật dữ liệu trong MongoDB\n",
    "        places_collection.update_one({'placeId': place_id},\n",
    "                                     {'$set': {'average_rating': new_average_rating}})\n",
    "\n",
    "        # Cập nhật dữ liệu trong MongoDB\n",
    "        places_collection.update_one({'placeId': place_id},\n",
    "                                     {'$set': {'average_predict_rating': new_average_predict_rating,\n",
    "                                               'total_rows': total_rows + 1}})\n",
    "\n",
    "last_consumer_time = 0\n",
    "while True:\n",
    "    try:\n",
    "        # Sắp xếp DataFrame theo thời gian cập nhật giảm dần và chỉ lấy dòng đầu tiên\n",
    "        newest_review_df = json_stream_df.sort(col(\"last_update_time\").desc()).limit(1)\n",
    "        temp_time = newest_review_df.select(\"last_update_time\").first()[0]\n",
    "        if temp_time > last_consumer_time:\n",
    "            last_consumer_time = temp_time\n",
    "        else:\n",
    "            # Nếu thời gian không lớn hơn, tiếp tục vòng lặp\n",
    "            continue\n",
    "\n",
    "        # newest_review_df = json_stream_df.limit(1)\n",
    "        newest_review_df_pandas = newest_review_df.toPandas()\n",
    "\n",
    "        # Check if the pandas DataFrame is empty\n",
    "        if newest_review_df_pandas.empty:\n",
    "            continue\n",
    "        newest_review_df_pandas = removeOtherLanguage(newest_review_df_pandas)\n",
    "        if newest_review_df_pandas.empty:\n",
    "            continue\n",
    "        \n",
    "        newest_review_df_pandas = unicode(newest_review_df_pandas)\n",
    "        newest_review_df_pandas['text'] = newest_review_df_pandas['text'].apply(remove_emojis)\n",
    "        newest_review_df_pandas = stickyPreprocess(newest_review_df_pandas)\n",
    "        newest_review_df_pandas = abbreviationPreprocess(newest_review_df_pandas)\n",
    "        newest_review_df_pandas[\"sentiment\"] = newest_review_df_pandas[\"sentences\"].apply(sentimentCal)\n",
    "\n",
    "        newest_review_df_pandas['sentiment'] = newest_review_df_pandas['sentiment'].apply(lambda sentiments: [\"neutral\" if sentiment is None else sentiment for sentiment in sentiments])\n",
    "\n",
    "        newest_review_df_pandas[\"text\"] = [item + \" .\" for item in newest_review_df_pandas[\"text\"]]\n",
    "        newest_review_df_pandas['publishedAtDate'] = newest_review_df_pandas['publishedAtDate'].apply(lambda x: formatToDatetime(x))\n",
    "        newest_review_df_pandas[\"reviewHour\"] = [item.hour for item in newest_review_df_pandas[\"publishedAtDate\"]]\n",
    "        newest_review_df_pandas[\"reviewLength\"] = [len(item) for item in newest_review_df_pandas[\"text\"]]\n",
    "\n",
    "        count_pos = newest_review_df_pandas['sentiment'].apply(lambda sentiments: sum(sentiment == \"positive\" for sentiment in sentiments))\n",
    "        count_neg = newest_review_df_pandas['sentiment'].apply(lambda sentiments: sum(sentiment == \"negative\" for sentiment in sentiments))\n",
    "\n",
    "        newest_review_df_pandas['num_sentiments'] = newest_review_df_pandas['sentiment'].apply(lambda sentiments: len(sentiments) if sentiments else 0)\n",
    "\n",
    "        newest_review_df_pandas['pos_prop'] = count_pos / newest_review_df_pandas['num_sentiments']\n",
    "        newest_review_df_pandas['neg_prop'] = count_neg / newest_review_df_pandas['num_sentiments']\n",
    "\n",
    "        X = newest_review_df_pandas[selected_columns].copy()\n",
    "        newest_review_df_pandas[\"Predict_rating\"] = model.predict(X)\n",
    "\n",
    "        # newest_review_df = newest_review_df.drop(columns = ['text'], ['pos_prop'], ['neg_prop'], [])\n",
    "        \n",
    "        # Chuyển DataFrame thành JSON string và lấy giá trị cột 'value'\n",
    "        # message_value = newest_review_df.toJSON().first()\n",
    "        json_string = newest_review_df_pandas.to_json(orient='records')\n",
    "        json_list = json.loads(json_string)\n",
    "        first_row = json_list[0]\n",
    "\n",
    "        # In ra giá trị để kiểm tra\n",
    "        #print(message_value)\n",
    "        print(first_row)\n",
    "\n",
    "        # Insert documents (rows) into the database's collection (table)\n",
    "        collection.insert_one(first_row)\n",
    "        \n",
    "        # Gọi hàm callback để cập nhật average_rating\n",
    "        update_average_rating(first_row)\n",
    "        sleep(10)\n",
    "        # clear_output(wait=True)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"break\")\n",
    "        break\n",
    "\n",
    "print(\"Live view ended...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d44e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "newest_review_df.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b60d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
